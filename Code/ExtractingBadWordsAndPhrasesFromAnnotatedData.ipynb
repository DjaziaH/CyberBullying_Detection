{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d465023",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Read the annotated data :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
<<<<<<< HEAD
=======
   "id": "903690b4",
>>>>>>> 20d7534fa0ea3bad2e6f02fae9792e7aeac462e6
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1 = pd.read_csv('../Data/data_1/PreProcessedYoutubeDataFileAndAnnotated.csv')\n",
    "data_2 = pd.read_csv('../Data/data_2/PreProcessedYoutubeDataFileAndAnnotated.csv')"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 3,
=======
   "execution_count": 4,
   "id": "d11280c6",
>>>>>>> 20d7534fa0ea3bad2e6f02fae9792e7aeac462e6
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data_1 = data_1.iloc[:,1:]\n",
    "data_2 = data_2.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Comments of the Algerian Dialect"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 4,
=======
   "execution_count": 5,
   "id": "d14aa022",
>>>>>>> 20d7534fa0ea3bad2e6f02fae9792e7aeac462e6
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_AD_comments(data):\n",
    "    for index in range(len(data)) : \n",
    "        if data.iloc[index][\"Algerian Dialect\"] == \"n\":\n",
    "            data.drop(data.index[index], inplace = True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 5,
=======
   "execution_count": 8,
   "id": "3989d696",
>>>>>>> 20d7534fa0ea3bad2e6f02fae9792e7aeac462e6
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1 = get_AD_comments(data_1)\n",
    "data_2 = get_AD_comments(data_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data_1 : 2567\n",
      "Data_2 : 6068\n"
     ]
    }
   ],
   "source": [
    "print(f'Data_1 : {len(data_1)}')\n",
    "print(f'Data_2 : {len(data_2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save only Algerian dialect comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1.to_csv('../Data/data_1/PreProcessedYoutubeDataFileAndAnnotated.csv')\n",
    "data_2.to_csv('../Data/data_2/PreProcessedYoutubeDataFileAndAnnotated.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get Offensive Comments from the data "
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 8,
=======
   "execution_count": 9,
   "id": "740e0c4c",
>>>>>>> 20d7534fa0ea3bad2e6f02fae9792e7aeac462e6
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Return Offensive comments from the data \n",
    "def get_offensive_comments(data):\n",
    "    \n",
    "    offensiveComment = pd.DataFrame(columns=['text'])\n",
    "    for index in range(len(data)):\n",
    "        if data.iloc[index][\"offensive/non offensive\"] == \"p\":\n",
    "            offensiveComment = offensiveComment.append({\"text\" : data.iloc[index][\"text\"]},ignore_index=True)\n",
    "    return offensiveComment\n"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 9,
=======
   "execution_count": 10,
   "id": "368ce2b0",
>>>>>>> 20d7534fa0ea3bad2e6f02fae9792e7aeac462e6
   "metadata": {},
   "outputs": [],
   "source": [
    "offensiveComment_1 = get_offensive_comments(data_1)\n",
    "offensiveComment_2 = get_offensive_comments(data_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Select comments with a length of 4 or less:"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 10,
=======
   "execution_count": 11,
   "id": "9346243e",
>>>>>>> 20d7534fa0ea3bad2e6f02fae9792e7aeac462e6
   "metadata": {},
   "outputs": [],
   "source": [
    "list_1_1 = []\n",
    "list_1_2 = []\n",
    "list_1_3 = []\n",
    "list_1_4 = []\n",
    "\n",
    "\n",
    "list_2_1 = []\n",
    "list_2_2 = []\n",
    "list_2_3 = []\n",
    "list_2_4 = []\n",
    "\n",
    "for index in range(len(offensiveComment_1)) : \n",
    "    comment = offensiveComment_1.iloc[index][\"text\"]\n",
    "    commentLength = len(comment.split(' '))\n",
    "\n",
    "    if(commentLength == 1) :\n",
    "        list_1_1.append(comment)\n",
    "    elif(commentLength == 2) : \n",
    "        list_1_2.append(comment)\n",
    "    elif(commentLength == 3) : \n",
    "        list_1_3.append(comment)\n",
    "    elif(commentLength == 4) : \n",
    "        list_1_4.append(comment)\n",
    "        \n",
    "for index in range(len(offensiveComment_2)) : \n",
    "    comment = offensiveComment_2.iloc[index][\"text\"]\n",
    "    commentLength = len(comment.split(' '))\n",
    "\n",
    "    if(commentLength == 1) :\n",
    "        list_2_1.append(comment)\n",
    "    elif(commentLength == 2) : \n",
    "        list_2_2.append(comment)\n",
    "    elif(commentLength == 3) : \n",
    "        list_2_3.append(comment)\n",
    "    elif(commentLength == 4) : \n",
    "        list_2_4.append(comment)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 11,
=======
   "execution_count": 14,
   "id": "e2e88b15",
>>>>>>> 20d7534fa0ea3bad2e6f02fae9792e7aeac462e6
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List 1 : 389\n",
      "List 2 : 704\n"
     ]
    }
   ],
   "source": [
    "new_bad_words_1 = list_1_1 + list_1_2 + list_1_3 + list_1_4\n",
    "print(f'List 1 : {len(new_bad_words_1)}')\n",
    "\n",
    "new_bad_words_2 = list_2_1 + list_2_2 + list_2_3 + list_2_4\n",
    "print(f'List 2 : {len(new_bad_words_2)}')"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 12,
=======
   "execution_count": 27,
   "id": "8f7f33df",
>>>>>>> 20d7534fa0ea3bad2e6f02fae9792e7aeac462e6
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1 = pd.DataFrame(new_bad_words_1)\n",
    "df_2 = pd.DataFrame(new_bad_words_2)"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1.columns = ['bad_word']\n",
    "df_2.columns = ['bad_word']"
=======
   "execution_count": 28,
   "id": "e69c6f69",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"../Data/new_bad_words\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e431388",
   "metadata": {},
   "source": [
    "### After getting the new list of bad words :\n",
    "we have checked if these are really bad words and are deleting some unnecessary words"
>>>>>>> 20d7534fa0ea3bad2e6f02fae9792e7aeac462e6
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1.to_csv(\"../Data/data_1/new_bad_words.csv\")\n",
    "df_2.to_csv(\"../Data/data_2/new_bad_words.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### After getting the new lists of bad words :\n",
    "we have deleted names of person from sentences, and removed repeated words in the same sentence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1_1 = pd.read_csv(\"../Data/data_1/new_bad_words_1.csv\")\n",
    "df_1_2 = pd.read_csv(\"../Data/data_2/new_bad_words_2.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New List 1 : 383\n",
      "New List 2 : 702\n"
     ]
    }
   ],
   "source": [
    "print(f'New List 1 : {len(df_1_1)}')\n",
    "print(f'New List 2 : {len(df_1_2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding the list to the dictionary :\n",
    "we have checked if these are really bad words and are deleting some unnecessary words"
=======
   "execution_count": 29,
   "id": "b990825a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>bad_word</th>\n",
       "      <th>lenght</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>بف</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>فايحا</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>شادي</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>نكم</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>رخيسا</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  bad_word  lenght\n",
       "0       بف       1\n",
       "1    فايحا       1\n",
       "2     شادي       1\n",
       "3      نكم       1\n",
       "4    رخيسا       1"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"../Data/new_bad_words.csv\")\n",
    "df = df[[\"bad_word\",\"lenght\"]]\n",
    "df.head()"
>>>>>>> 20d7534fa0ea3bad2e6f02fae9792e7aeac462e6
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a0db969",
   "metadata": {},
   "source": [
    "### Add the new words to the dictionary :"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 17,
=======
   "execution_count": 30,
   "id": "a3f7483d",
>>>>>>> 20d7534fa0ea3bad2e6f02fae9792e7aeac462e6
   "metadata": {},
   "outputs": [],
   "source": [
    "def adding_words_to_dictionary_with_frequency(new_list):\n",
    "    dictionary = pd.read_csv('../Data/dictionaries/dictionaryWithFrequency.csv')\n",
    "    dictionary = dict(zip(dictionary[\"bad_word\"], dictionary[\"frequency\"]))\n",
    "\n",
    "    new_bad_words = new_list[[\"bad_word\"]]\n",
    "\n",
    "    for i in new_bad_words.index:\n",
    "        new_word = (new_bad_words.loc[i][\"bad_word\"])\n",
    "        if new_word in dictionary :\n",
    "            dictionary[new_word] = (dictionary[new_word] + 1)\n",
    "        else :\n",
    "            dictionary[new_word] = 1\n",
    "    return dictionary "
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 18,
=======
   "execution_count": 31,
   "id": "38e191ee",
>>>>>>> 20d7534fa0ea3bad2e6f02fae9792e7aeac462e6
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = pd.read_csv('../Data/dictionaries/dictionaryWithFrequency.csv')\n",
    "dictionary = dict(zip(dictionary[\"bad_word\"], dictionary[\"frequency\"]))"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 19,
=======
   "execution_count": 32,
   "id": "1d7c2ebb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "218\n",
      "385\n"
     ]
    }
   ],
   "source": [
    "print(len(dictionary))\n",
    "print(len(bad_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "265ec0bc",
>>>>>>> 20d7534fa0ea3bad2e6f02fae9792e7aeac462e6
   "metadata": {},
   "outputs": [],
   "source": [
    "df_1_1 = df_1_1.iloc[:,1:]\n",
    "df_1_2 = df_1_2.iloc[:,1:]"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_dict_1 = adding_words_to_dictionary_with_frequency(df_1_1)\n",
    "new_dict_2 = adding_words_to_dictionary_with_frequency(df_1_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dictionary : 218\n",
      "New dictionary 1 : 585\n",
      "New dictionary 2 : 897\n"
     ]
    }
   ],
   "source": [
    "print(f'Dictionary : {len(dictionary)}')\n",
    "print(f'New dictionary 1 : {len(new_dict_1)}')\n",
    "print(f'New dictionary 2 : {len(new_dict_2)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save new dictionaries : "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(list(new_dict_1.items()),columns = ['bad_word','frequency'] ).to_csv('../Data/dictionaries/dictionary_with_new_bad_words_1.csv')\n",
    "pd.DataFrame(list(new_dict_2.items()),columns = ['bad_word','frequency'] ).to_csv('../Data/dictionaries/dictionary_with_new_bad_words_2.csv')"
=======
   "execution_count": 36,
   "id": "cb0e22f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "582\n"
     ]
    }
   ],
   "source": [
    "print(len(new_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "fddcf8ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(list(new_dict.items()),columns = ['bad_word','frequency'] ).to_csv('../Data/dictionary_with_new_bad_words.csv')"
>>>>>>> 20d7534fa0ea3bad2e6f02fae9792e7aeac462e6
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
